{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4aa07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "796f1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Data/\"\n",
    "\n",
    "# Path to data\n",
    "patients_path =  data_dir +'patients.csv'\n",
    "admissions_path = data_dir +'admissions.csv'\n",
    "diagnoses_path = data_dir +'diagnoses_icd.csv'\n",
    "lab_events_path = data_dir +'labevents_sample.csv'\n",
    "d_icd_labs_path =data_dir +'d_labitems.csv'\n",
    "d_icd_diagnoses_path = data_dir +'d_icd_diagnoses.csv'\n",
    "d_icd_procedures_path = data_dir +'d_icd_procedures.csv'\n",
    "procedures_path =data_dir + 'procedures_icd.csv'\n",
    "notes_path =data_dir + 'Notes.csv'\n",
    "\n",
    "# Load the data\n",
    "patients = pd.read_csv(patients_path, usecols=['subject_id', 'gender'])\n",
    "admissions = pd.read_csv(admissions_path, usecols=['subject_id', 'hadm_id', 'race'])\n",
    "diagnoses = pd.read_csv(diagnoses_path, usecols=['subject_id', 'hadm_id', 'icd_code'])\n",
    "d_icd_diagnoses = pd.read_csv(d_icd_diagnoses_path, usecols=['icd_code', 'long_title'])\n",
    "lab_events = pd.read_csv(lab_events_path, usecols=['subject_id', 'hadm_id', 'itemid', 'valuenum', 'ref_range_lower','ref_range_upper','flag'])\n",
    "d_icd_labs = pd.read_csv(d_icd_labs_path, usecols=['itemid', 'label'])\n",
    "procedures = pd.read_csv(procedures_path, usecols=['subject_id', 'hadm_id', 'icd_code'])\n",
    "d_icd_procedures = pd.read_csv(d_icd_procedures_path, usecols=['icd_code', 'long_title'])\n",
    "notes = pd.read_csv(notes_path, usecols=['subject_id', 'hadm_id', 'Symptoms', 'allergies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb3c17",
   "metadata": {},
   "source": [
    "Merging the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219adb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataframes...\n",
      "Diagnoses after merge: (6484228, 4)\n",
      "   subject_id   hadm_id icd_code  \\\n",
      "0    10000032  22595853     5723   \n",
      "1    10000032  22595853    78959   \n",
      "2    10000032  22595853     5715   \n",
      "3    10000032  22595853    07070   \n",
      "4    10000032  22595853      496   \n",
      "\n",
      "                                          long_title  \n",
      "0                                Portal hypertension  \n",
      "1                                      Other ascites  \n",
      "2      Cirrhosis of liver without mention of alcohol  \n",
      "3  Unspecified viral hepatitis C without hepatic ...  \n",
      "4  Chronic airway obstruction, not elsewhere clas...  \n",
      "Procedures after merge: (859708, 4)\n",
      "   subject_id   hadm_id icd_code  \\\n",
      "0    10000032  22595853     5491   \n",
      "1    10000032  22841357     5491   \n",
      "2    10000032  25742920     5491   \n",
      "3    10000068  25022803     8938   \n",
      "4    10000117  27988844  0QS734Z   \n",
      "\n",
      "                                          long_title  \n",
      "0                    Percutaneous abdominal drainage  \n",
      "1                    Percutaneous abdominal drainage  \n",
      "2                    Percutaneous abdominal drainage  \n",
      "3        Other nonoperative respiratory measurements  \n",
      "4  Reposition Left Upper Femur with Internal Fixa...  \n",
      "Lab events after merge: (96695, 11)\n",
      "Processing lab events...\n",
      "Filtered lab events (non-null flag): (96695, 11)\n",
      "Lab events after filtering Unknown status: (94241, 12)\n",
      "Lab grouped shape: (1381, 2)\n",
      "      hadm_id                                               labs\n",
      "0  20010003.0  [51221_Hematocrit_Below, 51222_Hemoglobin_Belo...\n",
      "1  20015927.0  [51221_Hematocrit_Below, 51222_Hemoglobin_Belo...\n",
      "2  20019162.0  [51221_Hematocrit_Below, 51222_Hemoglobin_Belo...\n",
      "3  20023045.0  [51221_Hematocrit_Below, 51222_Hemoglobin_Belo...\n",
      "4  20023531.0  [50912_Creatinine_Above, 50931_Glucose_Above, ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging dataframes...\")\n",
    "\n",
    "# Merge diagnoses with d_icd_diagnoses\n",
    "diagnoses = diagnoses.merge(d_icd_diagnoses[['icd_code', 'long_title']], \n",
    "                            on='icd_code', how='left')\n",
    "print(f\"Diagnoses after merge: {diagnoses.shape}\")\n",
    "print(diagnoses.head())\n",
    "\n",
    "# Merge procedures with d_icd_procedures\n",
    "procedures = procedures.merge(d_icd_procedures[['icd_code', 'long_title']], \n",
    "                              on='icd_code', how='left')\n",
    "print(f\"Procedures after merge: {procedures.shape}\")\n",
    "print(procedures.head())\n",
    "\n",
    "# Merge lab_events with d_icd_labs (d_labitems)\n",
    "lab_events_with_desc = lab_events.merge(d_icd_labs[['itemid', 'label']], \n",
    "                                       on='itemid', how='left')\n",
    "print(f\"Lab events after merge: {lab_events_with_desc.shape}\")\n",
    "\n",
    "# Process lab events (abnormal results only, with range status)\n",
    "print(\"Processing lab events...\")\n",
    "lab_events_with_desc['lab_result'] = (\n",
    "    lab_events_with_desc['itemid'].astype(str) + '_' + \n",
    "    lab_events_with_desc['label'].fillna('Unknown')\n",
    ")\n",
    "lab_events_with_desc = lab_events_with_desc.dropna(subset=['hadm_id', 'flag'])\n",
    "print(f\"Filtered lab events (non-null flag): {lab_events_with_desc.shape}\")\n",
    "\n",
    "if lab_events_with_desc.empty:\n",
    "    print(\"WARNING: No abnormal lab events found.\")\n",
    "    lab_grouped = pd.DataFrame(columns=['hadm_id', 'labs'])\n",
    "else:\n",
    "    # Categorize lab results as Below, Above, or Unknown\n",
    "    def classify_range(row):\n",
    "        if pd.notnull(row['valuenum']) and pd.notnull(row['ref_range_lower']) and row['valuenum'] < row['ref_range_lower']:\n",
    "            return 'Below'\n",
    "        elif pd.notnull(row['valuenum']) and pd.notnull(row['ref_range_upper']) and row['valuenum'] > row['ref_range_upper']:\n",
    "            return 'Above'\n",
    "        return 'Unknown'\n",
    "\n",
    "    lab_events_with_desc['range_status'] = lab_events_with_desc.apply(classify_range, axis=1)\n",
    "    lab_events_with_desc['lab_result'] = (\n",
    "        lab_events_with_desc['itemid'].astype(str) + '_' + \n",
    "        lab_events_with_desc['label'].fillna('Unknown') + '_' + \n",
    "        lab_events_with_desc['range_status']\n",
    "    )\n",
    "    lab_events_with_desc = lab_events_with_desc[lab_events_with_desc['range_status'] != 'Unknown']\n",
    "    print(f\"Lab events after filtering Unknown status: {lab_events_with_desc.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10b5053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab grouped shape: (1381, 2)\n",
      "      hadm_id                                               labs\n",
      "0  20010003.0  [51221_Hematocrit_Below, 51222_Hemoglobin_Belo...\n",
      "1  20015927.0  [51221_Hematocrit_Below, 51222_Hemoglobin_Belo...\n",
      "2  20019162.0  [51221_Hematocrit_Below, 51222_Hemoglobin_Belo...\n",
      "3  20023045.0  [51221_Hematocrit_Below, 51222_Hemoglobin_Belo...\n",
      "4  20023531.0  [50912_Creatinine_Above, 50931_Glucose_Above, ...\n"
     ]
    }
   ],
   "source": [
    "# Group lab events by hadm_id\n",
    "lab_grouped = (lab_events_with_desc.groupby('hadm_id')['lab_result']\n",
    "               .apply(lambda x: list(x.unique()))\n",
    "               .reset_index()\n",
    "               .rename(columns={'lab_result': 'labs'}))\n",
    "print(f\"Lab grouped shape: {lab_grouped.shape}\")\n",
    "print(lab_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a25680de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procedures grouped shape: (287504, 2)\n",
      "    hadm_id                                         procedures\n",
      "0  20000041                      [8154_Total knee replacement]\n",
      "1  20000045  [3E0436Z_Introduction of Nutritional Substance...\n",
      "2  20000069  [0KQM0ZZ_Repair Perineum Muscle, Open Approach...\n",
      "3  20000102  [7359_Other manually assisted delivery, 7309_O...\n",
      "4  20000147  [02100Z9_Bypass Coronary Artery, One Artery fr...\n"
     ]
    }
   ],
   "source": [
    "procedures['combined_title'] = (\n",
    "    procedures['icd_code'].astype(str) + '_' + \n",
    "    procedures['long_title'].fillna('Unknown')\n",
    ")\n",
    "\n",
    "# Group procedures by hadm_id, collecting unique combined titles\n",
    "procedures_grouped = (procedures.groupby('hadm_id')['combined_title']\n",
    "                      .apply(lambda x: list(x.unique()))\n",
    "                      .reset_index()\n",
    "                      .rename(columns={'combined_title': 'procedures'}))\n",
    "\n",
    "# Print shape and sample of grouped procedures\n",
    "print(f\"Procedures grouped shape: {procedures_grouped.shape}\")\n",
    "print(procedures_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94f37657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnoses grouped shape: (545497, 2)\n",
      "    hadm_id                                         procedures\n",
      "0  20000041                      [8154_Total knee replacement]\n",
      "1  20000045  [3E0436Z_Introduction of Nutritional Substance...\n",
      "2  20000069  [0KQM0ZZ_Repair Perineum Muscle, Open Approach...\n",
      "3  20000102  [7359_Other manually assisted delivery, 7309_O...\n",
      "4  20000147  [02100Z9_Bypass Coronary Artery, One Artery fr...\n"
     ]
    }
   ],
   "source": [
    "# Group diagnoses by hadm_id\n",
    "diagnoses_grouped = (diagnoses.groupby('hadm_id')['icd_code'] #icd_code\n",
    "                     .apply(lambda x: list(x.unique()))\n",
    "                     .reset_index()\n",
    "                     .rename(columns={'icd_codeicd_code': 'diagnoses'}))\n",
    "print(f\"Diagnoses grouped shape: {diagnoses_grouped.shape}\")\n",
    "print(procedures_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "527f8c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notes grouped shape: (331793, 3)\n",
      "Sample of grouped notes:\n",
      "    hadm_id                                           Symptoms  \\\n",
      "0  20000019  [Symptom_nausea/vomiting, Symptom_flank_pain, ...   \n",
      "1  20000024               [Symptom_weakness, Symptom_diarrhea]   \n",
      "2  20000034                                                 []   \n",
      "3  20000041                              [Symptom_l_knee_pain]   \n",
      "4  20000057  [Symptom_ankle_pain_(s/p_mechanical_fall), Sym...   \n",
      "\n",
      "                                           allergies  \n",
      "0  [Allergy_no_known_allergies_/_adverse_drug_rea...  \n",
      "1                                  [Allergy_aspirin]  \n",
      "2  [Allergy_no_known_allergies_/_adverse_drug_rea...  \n",
      "3                                    [Allergy_latex]  \n",
      "4  [Allergy_no_known_allergies_/_adverse_drug_rea...  \n"
     ]
    }
   ],
   "source": [
    "notes = pd.read_csv(notes_path, usecols=['hadm_id', 'Symptoms', 'allergies'])\n",
    "\n",
    "# Preprocess Symptoms and allergies to ensure they are lists with prefixed, formatted items\n",
    "def format_items(value, prefix):\n",
    "    if pd.isna(value) or value is None or value == '':\n",
    "        return []\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            # Split by comma, clean, and format each item\n",
    "            items = [item.strip().lower().replace(' ', '_') for item in value.split(',') if item.strip() and item.lower() != 'none']\n",
    "            return [f\"{prefix}{item}\" for item in items]\n",
    "        if isinstance(value, list):\n",
    "            # Clean and format list items\n",
    "            items = [item.strip().lower().replace(' ', '_') for item in value if isinstance(item, str) and item.strip() and item.lower() != 'none']\n",
    "            return [f\"{prefix}{item}\" for item in items]\n",
    "        print(f\"Unexpected value type for {prefix}: {value} (type: {type(value)})\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {prefix} value {value}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Apply formatting and ensure no NaN values remain\n",
    "notes['Symptoms'] = notes['Symptoms'].apply(lambda x: format_items(x, 'Symptom_'))\n",
    "notes['allergies'] = notes['allergies'].apply(lambda x: format_items(x, 'Allergy_'))\n",
    "\n",
    "# Group by hadm_id, keeping Symptoms and allergies separate\n",
    "notes_grouped = notes.groupby('hadm_id').agg({\n",
    "    'Symptoms': lambda x: list(set(item for sublist in x for item in sublist if isinstance(sublist, list))),\n",
    "    'allergies': lambda x: list(set(item for sublist in x for item in sublist if isinstance(sublist, list)))\n",
    "}).reset_index()\n",
    "\n",
    "# Print shape and sample of grouped notes\n",
    "print(f\"\\nNotes grouped shape: {notes_grouped.shape}\")\n",
    "print(\"Sample of grouped notes:\")\n",
    "print(notes_grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11aeed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admissions with patients shape: (546028, 4)\n"
     ]
    }
   ],
   "source": [
    "# Admissions with patients\n",
    "admissions_patients = admissions.merge(patients[['subject_id', 'gender']], on='subject_id', how='left')\n",
    "print(f\"Admissions with patients shape: {admissions_patients.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c838e20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data for transactions...\n",
      "Transactions dataframe shape: (546028, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create base dataframe with all hadm_ids\n",
    "transactions_df = pd.DataFrame({'hadm_id': admissions['hadm_id'].unique()})\n",
    "\n",
    "# Merge all grouped data\n",
    "print(\"Combining data for transactions...\")\n",
    "transactions_df = transactions_df.merge(admissions_patients[['hadm_id', 'gender', 'race']], on='hadm_id', how='left')\n",
    "transactions_df = transactions_df.merge(diagnoses_grouped, on='hadm_id', how='left')\n",
    "transactions_df = transactions_df.merge(procedures_grouped, on='hadm_id', how='left')\n",
    "transactions_df = transactions_df.merge(lab_grouped, on='hadm_id', how='left')\n",
    "transactions_df = transactions_df.merge(notes_grouped, on='hadm_id', how='left')\n",
    "print(f\"Transactions dataframe shape: {transactions_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "240ca92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample transactions:\n",
      "Transaction 1: ['D_5723_Portal hypertension', 'D_78959_Other ascites', 'D_5715_Cirrhosis of liver without mention of alcohol', 'D_07070_Unspecified viral hepatitis C without hepatic coma', 'D_496_Chronic airway obstruction, not elsewhere classified', 'D_29680_Bipolar disorder, unspecified', 'D_30981_Posttraumatic stress disorder', 'D_V1582_Personal history of tobacco use', 'P_5491_Percutaneous abdominal drainage', 'L_51514_Urobilinogen_Above']...\n",
      "Transaction 2: ['D_07071_Unspecified viral hepatitis C with hepatic coma', 'D_78959_Other ascites', 'D_2875_Thrombocytopenia, unspecified', 'D_2761_Hyposmolality and/or hyponatremia', 'D_496_Chronic airway obstruction, not elsewhere classified', 'D_5715_Cirrhosis of liver without mention of alcohol', 'D_V08_Asymptomatic human immunodeficiency virus [HIV] infection status', 'D_3051_Tobacco use disorder', 'P_5491_Percutaneous abdominal drainage', 'L_51516_WBC_Above']...\n",
      "Transaction 3: ['D_07054_Chronic hepatitis C without mention of hepatic coma', 'D_78959_Other ascites', 'D_V462_Other dependence on machines, supplemental oxygen', 'D_V462_Person on outside of car injured in collision with other nonmotor vehicle in nontraffic accident', 'D_5715_Cirrhosis of liver without mention of alcohol', 'D_2767_Hyperpotassemia', 'D_2761_Hyposmolality and/or hyponatremia', 'D_496_Chronic airway obstruction, not elsewhere classified', 'D_V08_Asymptomatic human immunodeficiency virus [HIV] infection status', 'D_3051_Tobacco use disorder']...\n",
      "Transaction 4: ['D_45829_Other iatrogenic hypotension', 'D_07044_Chronic hepatitis C with hepatic coma', 'D_7994_Cachexia', 'D_2761_Hyposmolality and/or hyponatremia', 'D_78959_Other ascites', 'D_2767_Hyperpotassemia', 'D_3051_Tobacco use disorder', 'D_V08_Asymptomatic human immunodeficiency virus [HIV] infection status', 'D_V4986_Do not resuscitate status', 'D_V462_Other dependence on machines, supplemental oxygen']...\n",
      "Transaction 5: ['D_30500_Alcohol abuse, unspecified', 'P_8938_Other nonoperative respiratory measurements', 'Gender_F', 'Race_WHITE']...\n"
     ]
    }
   ],
   "source": [
    "# Generate transactions\n",
    "transactions = []\n",
    "for _, row in transactions_df.iterrows():\n",
    "    transaction = []\n",
    "    \n",
    "    # Helper function to safely add items\n",
    "    def add_items(items, prefix=''):\n",
    "        if isinstance(items, list):\n",
    "            transaction.extend([f\"{prefix}{item}\" for item in items if pd.notna(item) and str(item).strip()])\n",
    "    \n",
    "    # Diagnoses\n",
    "    if 'diagnoses' in row:\n",
    "        add_items(row['diagnoses'], 'D_')\n",
    "    \n",
    "    # Procedures\n",
    "    if 'procedures' in row:\n",
    "        add_items(row['procedures'], 'P_')\n",
    "    \n",
    "    # Lab results\n",
    "    if 'labs' in row:\n",
    "        add_items(row['labs'], 'L_')\n",
    "    \n",
    "    # Gender\n",
    "    if 'gender' in row and pd.notna(row['gender']):\n",
    "        transaction.append(f\"Gender_{row['gender']}\")\n",
    "    \n",
    "    # Race\n",
    "    if 'race' in row and pd.notna(row['race']):\n",
    "        transaction.append(f\"Race_{row['race'].replace(' ', '_')}\")\n",
    "    \n",
    "    # Symptoms\n",
    "    if 'Symptoms' in row:\n",
    "        add_items(row['Symptoms'])\n",
    "    \n",
    "    # Allergies\n",
    "    if 'allergies' in row:\n",
    "        add_items(row['allergies'])\n",
    "    \n",
    "    transactions.append(transaction)\n",
    "\n",
    "# Print sample transactions\n",
    "print(\"\\nSample transactions:\")\n",
    "for i, t in enumerate(transactions[:5], 1):\n",
    "    print(f\"Transaction {i}: {t[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1a17841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions saved to transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with hadm_id and transactions\n",
    "transactions_df_out = pd.DataFrame({\n",
    "    'hadm_id': transactions_df['hadm_id'],\n",
    "    'transaction': transactions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "transactions_df_out.to_csv(\"transactions.csv\", index=False)\n",
    "print(\"Transactions saved to transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b0e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4236\\1450817909.py:18: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df_onehot = pd.DataFrame.sparse.from_spmatrix(onehot, columns=encoder.columns_)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize encoder and get item frequencies\n",
    "encoder = TransactionEncoder()\n",
    "encoder.fit(transactions)  # Fit without transforming\n",
    "item_counts = pd.Series(encoder.columns_).value_counts()\n",
    "\n",
    "# Step 2: Keep only items appearing >= min_freq times\n",
    "min_freq = 10  # Adjust based on your data\n",
    "frequent_items = item_counts[item_counts >= min_freq].index.tolist()\n",
    "\n",
    "# Step 3: Filter transactions to include only frequent items\n",
    "filtered_transactions = [\n",
    "    [item for item in txn if item in frequent_items] \n",
    "    for txn in transactions\n",
    "]\n",
    "\n",
    "# Step 4: Now one-hot encode the filtered transactions\n",
    "onehot = encoder.fit_transform(transactions, sparse=True)\n",
    "df_onehot = pd.DataFrame.sparse.from_spmatrix(onehot, columns=encoder.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = fpgrowth(df_onehot, min_support=0.1, use_colnames=True)\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.4)\n",
    "\n",
    "print(\"Frequent Itemsets:\\n\", frequent_itemsets)\n",
    "print(\"\\nAssociation Rules:\\n\", rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d389a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets.to_csv(\"frequent_itemsets.csv\", index=False)\n",
    "rules.to_csv(\"association_rules.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
